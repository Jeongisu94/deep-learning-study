{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c) #overflow방지\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t): #y와 t는 넘파이 배열  \n",
    "    delta = 1e-7\n",
    "\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None  \n",
    "        self.y = None  \n",
    "        self.t = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t  \n",
    "        self.y = softmax(x) \n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "\n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1): # 배치의 수로 나눠서 데이터 1개당 오차를 하류로 전파\n",
    "        batch_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxWithLoss의 순전파 결과 ***잘 못 예측한 경우*** : 1.239830715341547 \n",
      "\n",
      "SoftmaxWithLoss의 순전파 결과 ***잘 예측한 경우*** : 0.5578356242191105 \n",
      "\n",
      "SoftmaxWithLoss의 역전파 결과 ***잘 못 예측한 경우*** : [[ 0.31987306 -0.71056689  0.39069383]] \n",
      "\n",
      "SoftmaxWithLoss의 역전파 결과 ***잘 예측한 경우*** : [[ 0.21484557 -0.42755339  0.21270782]]\n"
     ]
    }
   ],
   "source": [
    "swl1 = SoftmaxWithLoss()\n",
    "swl2 = SoftmaxWithLoss()\n",
    "\n",
    "truth_label1 = np.array([[0 ,1 ,0]])\n",
    "truth_label2 = np.array([[0, 1, 0]])\n",
    "\n",
    "y_predict1 = np.array([[0.3, 0.2, 0.5]])\n",
    "y_predict2 = np.array([[0.01, 0.99, 0.0]])\n",
    "\n",
    "forward1 = swl1.forward(y_predict1, truth_label1)\n",
    "print(\"SoftmaxWithLoss의 순전파 결과 ***잘 못 예측한 경우*** :\", forward1,\"\\n\")\n",
    "\n",
    "forward2 = swl2.forward(y_predict2, truth_label2)\n",
    "print(\"SoftmaxWithLoss의 순전파 결과 ***잘 예측한 경우*** :\", forward2,\"\\n\")\n",
    "\n",
    "backward1 = swl1.backward()\n",
    "print(\"SoftmaxWithLoss의 역전파 결과 ***잘 못 예측한 경우*** :\", backward1,\"\\n\")\n",
    "\n",
    "backward2 = swl2.backward()\n",
    "print(\"SoftmaxWithLoss의 역전파 결과 ***잘 예측한 경우*** :\", backward2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
